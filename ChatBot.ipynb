{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ChatBot.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdVwPVeaDi7b"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy  as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open(\"train_qa-220120-145526.txt\",\"rb\") as fp:\n",
        "    train_data = pickle.load(fp)"
      ],
      "metadata": {
        "id": "pciTrt1xDj0n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "3f33f227-0401-421e-e23f-ca7062991664"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c1bc76c98dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_qa-220120-145526.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_qa-220120-145526.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data\n",
        "print(len(train_data))"
      ],
      "metadata": {
        "id": "DmXPQtVwDnAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"test_qa-220120-145430.txt\",\"rb\") as fp:\n",
        "    test_data = pickle.load(fp)"
      ],
      "metadata": {
        "id": "makcpvuMEu-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data\n",
        "print(len(test_data))"
      ],
      "metadata": {
        "id": "4GU2kn8VEytG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data[0]"
      ],
      "metadata": {
        "id": "E-5CwHwyEzpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][0])"
      ],
      "metadata": {
        "id": "-NZc5_jSFRII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "' '.join(train_data[0][1])"
      ],
      "metadata": {
        "id": "91nKwraUFUA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[0][2]"
      ],
      "metadata": {
        "id": "l5W7o3kjFWAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set up vocublary\n",
        "vocab = set()"
      ],
      "metadata": {
        "id": "UJ0T7h34FYGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = test_data+train_data"
      ],
      "metadata": {
        "id": "TzA-QetmFaMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(all_data)"
      ],
      "metadata": {
        "id": "pymSW1O6FcJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for story, question, answer in all_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))"
      ],
      "metadata": {
        "id": "zZVofQBIFeYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add('yes')\n",
        "vocab.add('no')"
      ],
      "metadata": {
        "id": "khJjtt9NFgRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "id": "6QWmiwh0FifZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)+1"
      ],
      "metadata": {
        "id": "WhNoDSFmFkbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for data in all_data:\n",
        "    print(data[0])\n",
        "    print(len(data[0]))\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "AZrZjYrmFmnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_story_len = max([len(data[0]) for data in all_data ])\n",
        "max_story_len"
      ],
      "metadata": {
        "id": "eXM4XgSxFodz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_question_len = max([len(data[1]) for data in all_data ])\n",
        "max_question_len"
      ],
      "metadata": {
        "id": "Pu15OrQgFs1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorize(convert dataset into mathematical form)\n",
        "vocab"
      ],
      "metadata": {
        "id": "5vMPCtQgFuy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "P0bRInGlFyUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(filters = [])"
      ],
      "metadata": {
        "id": "8dxPCVkVF072"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.fit_on_texts(vocab)"
      ],
      "metadata": {
        "id": "2fej-ijlRkNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "id": "rnlaoVCJRsip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text = []\n",
        "train_question_text = []\n",
        "train_answers = []\n",
        "\n",
        "for story, question, answer in train_data:\n",
        "    train_story_text.append(story)\n",
        "    train_question_text.append(question)"
      ],
      "metadata": {
        "id": "_vrPxr9dRvl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
      ],
      "metadata": {
        "id": "pLJ_48GVSrV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_text)"
      ],
      "metadata": {
        "id": "mPJQdZ15S_FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_story_seq)"
      ],
      "metadata": {
        "id": "iYIsti-5TBsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_seq"
      ],
      "metadata": {
        "id": "DuPMPhaATD7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_story_text"
      ],
      "metadata": {
        "id": "elqhMukMTMGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_stories(data, word_index = tokenizer.word_index,\n",
        "    max_story_len = max_story_len, max_question_len = max_question_len):\n",
        "    X = [] #stories\n",
        "    Xq = [] #query/question\n",
        "    Y = [] #answer\n",
        "\n",
        "    for story, query, answer in data:\n",
        "        x = [word_index[word.lower()] for word in story]\n",
        "        xq = [word_index[word.lower()] for word in query]\n",
        "        y = np.zeros(len(word_index)+1)\n",
        "        y[word_index[answer]] = 1\n",
        "\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "    \n",
        "        return(pad_sequences(X, maxlen = max_story_len),\n",
        "           pad_sequences(Xq, maxlen = max_question_len),\n",
        "           np.array(Y) )"
      ],
      "metadata": {
        "id": "3v-vQ0WLTji6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train, queries_train, answer_train = vectorize_stories(train_data)\n",
        "inputs_test, queries_test, answer_test = vectorize_stories(test_data)"
      ],
      "metadata": {
        "id": "m2dLuZ57WKU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs_train"
      ],
      "metadata": {
        "id": "Ofa8kLbAnEOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries_test"
      ],
      "metadata": {
        "id": "-PWQJtEqqxpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_test"
      ],
      "metadata": {
        "id": "VoJAUUNKq0jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['yes']"
      ],
      "metadata": {
        "id": "pfhwGnjMq2YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index['no']"
      ],
      "metadata": {
        "id": "JZqsZeKGq_VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, add, Dot, concatenate, LSTM"
      ],
      "metadata": {
        "id": "at7-y7r8rGVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequence = Input((max_story_len,))\n",
        "question = Input((max_question_len,))"
      ],
      "metadata": {
        "id": "E9wNJmursZP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input Encoder m\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim = vocab_len, output_dim = 64))\n",
        "input_encoder_m.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "_ma33LdltC9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Input Encoder c\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim = vocab_len, output_dim = max_question_len))\n",
        "input_encoder_c.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "g2w2cbCet52h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Questions Encoder\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim = vocab_len, output_dim = 64, input_length = max_question_len))\n",
        "question_encoder.add(Dropout(0.3))"
      ],
      "metadata": {
        "id": "iS-87gnIuRpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Encode the sequences\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "question_encoded = question_encoder(question)"
      ],
      "metadata": {
        "id": "HnRZY7xh6zDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match = tf.keras.layers.Dot(axes=(2, 2))([input_encoded_m, question_encoded])\n",
        "match = Activation('softmax')(match)"
      ],
      "metadata": {
        "id": "XWsjmPRy7fk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = add([match , input_encoded_c])\n",
        "response = Permute((2,1))(response)"
      ],
      "metadata": {
        "id": "lITRCzxU8MZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Concatenate\n",
        "answer = concatenate([response, question_encoded])"
      ],
      "metadata": {
        "id": "ZGghwzcixTVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "id": "Z_dPtLoY2Qff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = LSTM(32)(answer)"
      ],
      "metadata": {
        "id": "AyWPSnCn2RCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = Dropout(0.5)(answer)\n",
        "answer = Dense(vocab_len)(answer)"
      ],
      "metadata": {
        "id": "PCibAgD42eXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer = Activation('softmax')(answer)"
      ],
      "metadata": {
        "id": "dQpYntI42kFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model([input_sequence,question],answer)\n",
        "# for a multi-class classification problem\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#model.compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "xlF12oP26pL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "BQ8Od68O62WM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit([inputs_train, queries_train], answer_train,\n",
        "                    batch_size = 32, epochs = 20,\n",
        "                    validation_data = ([inputs_test, queries_test], answer_test)\n",
        "                    )"
      ],
      "metadata": {
        "id": "OPKJT_m68GQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print(history.history.keys())\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title(\"Model Accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.legend(['train','test'], loc = 'upper right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GDv_wdxD-0y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save\n",
        "model.save(\"chatbot_model\")"
      ],
      "metadata": {
        "id": "G5Vcg00C_lh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evolution on the test set\n",
        "model.load_weights(\"chatbot_model\")"
      ],
      "metadata": {
        "id": "HryReB3lDzb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_results = model.predict(([inputs_test,queries_test]))"
      ],
      "metadata": {
        "id": "PaiFN3xZGRs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0][0]"
      ],
      "metadata": {
        "id": "Yl9VWVk3GrBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story = ' '.join(word for word in test_data[0][0])"
      ],
      "metadata": {
        "id": "JQPXxIV-GvE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "story"
      ],
      "metadata": {
        "id": "OQLeFLqeHgHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = ' '.join(word for word in test_data[0][1])"
      ],
      "metadata": {
        "id": "hzBZrnwQHje0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query"
      ],
      "metadata": {
        "id": "E1JWXuvXH0Ul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0][2]"
      ],
      "metadata": {
        "id": "qiLeThdDH0-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_max = np.argmax(pred_results[0])\n",
        "\n",
        "for key, value in tokenizer.word_index.items():\n",
        "    if value==val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is \",k)\n",
        "print(\"Probability of certainity \", pred_results[0][val_max])"
      ],
      "metadata": {
        "id": "-SF_DStKH3sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "metadata": {
        "id": "ct0q_ZohJYYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_story = \"Mary dropped the football . Sandra is the in kitchen\""
      ],
      "metadata": {
        "id": "iW0pCA53KKCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_story.split(\" \")"
      ],
      "metadata": {
        "id": "6i-7ddKIKysC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_question = \"Is Sandra in the kitchen ?\"\n"
      ],
      "metadata": {
        "id": "-4ScWUyGKz3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_question.split(\" \")"
      ],
      "metadata": {
        "id": "XvWNGzs3K-kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_answer = \"yes\"\n",
        "my_answer.split(\" \")\n"
      ],
      "metadata": {
        "id": "l7YmP9ckuisJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_data = [([my_story.split(), my_question.split(),'yes'])]\n",
        "my_data"
      ],
      "metadata": {
        "id": "OKixHcY3LA34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_sty, my_ques, my_ans = vectorize_stories(my_data)\n",
        "#my_sty = (my_story.split())\n",
        "#my_ques = my_question.split()\n",
        "#my_ans = 'yes'\n",
        "#my_sty = my_data[0][0]\n",
        "#my_ques = my_data[0][1]\n",
        "#my_ans = my_data[0][2]\n",
        "#my_ans = vectorize_stories(my_data)\n",
        "#my_sty = (my_story.split())\n",
        "#my_ques = my_question.split()\n",
        "#my_ans = 'yes'\n",
        "print(my_ans)\n"
      ],
      "metadata": {
        "id": "IYa8DdCWOvpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#pred_results = model.predict(([inputs_test,queries_test]))\n",
        "pred_res = model.predict(([my_sty,my_ques]))\n",
        "pred_res"
      ],
      "metadata": {
        "id": "I6LfLF_JPDOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_max = np.argmax(pred_res[0])\n",
        "\n",
        "for key, value in tokenizer.word_index.items():\n",
        "    if value==val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is \",k)\n",
        "print(\"Probability of certainity \", pred_res[0][val_max])"
      ],
      "metadata": {
        "id": "pu9Qy7QLUd1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.clear()\n",
        "print(vocab)\n",
        "for story, question, answer in my_data:\n",
        "    vocab = vocab.union(set(story))\n",
        "    vocab = vocab.union(set(question))\n",
        "print(vocab)"
      ],
      "metadata": {
        "id": "YQvPQEqfU-z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.add('yes')\n",
        "vocab"
      ],
      "metadata": {
        "id": "dqmGpgmeSq7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_max = np.argmax(pred_res[0])\n",
        "\n",
        "for key, value in tokenizer.word_index.items():\n",
        "    if value==val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is \",k)\n",
        "print(\"Probability of certainity \", pred_res[0][val_max])"
      ],
      "metadata": {
        "id": "KlR8rsh6SxNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(filters= [])\n",
        "tk.fit_on_texts(vocab)\n",
        "print(tk.word_index)\n",
        "print(tk.word_index.items())"
      ],
      "metadata": {
        "id": "qjFx_tIlS0Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_max = np.argmax(pred_res[0])\n",
        "#print(val_max)\n",
        "print(pred_res[0])\n",
        "for key, value in tk.word_index.items():\n",
        "    if value==val_max:\n",
        "        k = key\n",
        "\n",
        "print(\"Predicted answer is \",k)\n",
        "print(\"Probability of certainity \", pred_res[0][val_max])"
      ],
      "metadata": {
        "id": "jUfpoAiNTBT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jY_bxSXgTNHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}